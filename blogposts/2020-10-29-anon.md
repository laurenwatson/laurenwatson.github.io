---
layout: post
title: 'Your Database isn&#39t Anonymous'
---

A simple approach to providing database privacy is to make the database anonymous by removing or obscuring any identifying features like name, zipcode, age and so on. As attractive as this idea might be, in the early days of data privacy it led to an unfortunate pattern that repeated itself again and again. The pattern began with a database being anonymized and released using the latest and greatest anonymity guarantee. Then, almost inevitably, someone would show that they could identify individuals from the supposedly anonymous database.

This led to a progression of definitions of anonymity, all of which ultimately fell short in some crucial way. These shortcomings were usually attributed to one of two main underlying issues:
1. Other databases may exist that contain overlapping information or individuals. It is usually extremely hard to find out about all existing (and future) databases of this form.
2. Data is often very high-dimensional.

In this post, we are going to discuss some of these definitions alongside some famous cases of broken anonymity.


1. [K-anonymity](#k-anonymity)
2. [l-diversity and t-closeness](#link)
3. [The Netflix Prize and Friends](#link)
netflix Prize
massacheusets hospital
4. [A Framework for Anonymity Attacks](#link)
5. [These Attacks Today](#link)

### k-Anonymity

In 1998, [Samarati and Sweeney](https://epic.org/privacy/reidentification/Samarati_Sweeney_paper.pdf) proposed an approach to releasing data privately using their idea of k-anonymity:

> A table provides *k-anonymity* if attempts to link explicitly identifying information to its contents ambiguously map the information to at least k entities.

This definition is based on finding:
- *identifiers*: attributes that unambiguously identify an individual and should be removed.
- *quasi-identifiers*: attributes that may be used to re-identify an individual and therefore need to be altered so that any combination of these is k-anonymous.

For example, identifiers could be a person's full name and social security number, quasi-identifiers could be age and zip code. The sensitive attribute that is being used in the database and we don't want to be matched to a particular person could be their salary. K-anonymity would ensure that no specific combination of the reported age and zip code would single out fewer than k possible entries, thus obscuring the salary.

While k-anonymity was an promising step towards a definition of privacy, it was [vulnerable](https://personal.utdallas.edu/~mxk055100/courses/privacy08f_files/ldiversity.pdf) to several varieties of attacks including those using background knowledge not identified when the anonymity was implemented and also when the attributes themselves did not vary enough. For example, if the disease a person has is 4-anonymous and all four people happen to have cancer, then the sensitive attribute has not been successfully hidden.

### l-diversity and t-closeness

Various extensions to k-anonymity were proposed to address the weaknesses identified. [Machanavajjhala et al.](https://personal.utdallas.edu/~mxk055100/courses/privacy08f_files/ldiversity.pdf) proposed an extension of k-anonymity, *l-diversity*, addressing the issue of attributes not varying enough to maintain privacy. However, l-diversity was again found be [less private than expected](https://crises-deim.urv.cat/webCrises/publications/bcpi/DomingoTorraPSAI2008.pdf) under certain circumstances. In particular, when the distribution of values for a certain attribute is skewed with only 1\% of an overall population having a given disease in comparison to a particular set of k entries which are indistinguishable from each other but where 50\% have the disease, then this would satisfy 2-diversity but would also reveal more about the individuals than intended.

[T-closeness](https://www.cs.purdue.edu/homes/ninghui/papers/t_closeness_icde07.pdf) was then proposed, addressing the issue of a skewed distribution of attributes by requiring that the distribution of values in any group of k-indistinguishable entries matches that of the overall database. However, it was found to severely limit the utility of the resulting database as it effectively [destroys the correlations between key attributes and the confidential attribute](https://crises-deim.urv.cat/webCrises/publications/bcpi/DomingoTorraPSAI2008.pdf).
